**ADR: 2025-11.6 - Выбор брокера доставки сообщений**

**Дата:** 19 ноября 2025 г.

**Статус:** Принято

**Контекст:**

Для реализации событийно-ориентированной архитектуры в сервисе парковки требуется выбрать брокер сообщений, который обеспечит надежную доставку событий между микросервисами. Ключевые требования включают высокую пропускную способность для обновлений статуса парковочных мест, гарантированную доставку для платежных операций, масштабируемость и отказоустойчивость.

**Рассмотренные варианты:**

1. **Apache Kafka:** Распределенная платформа потоковой обработки с высокой пропускной способностью
2. **RabbitMQ:** Классический message broker с поддержкой различных протоколов и паттернов
3. **NATS/JetStream:** Легковесный брокер с высокой производительностью и persistence
4. **Azure Service Bus/AWS SQS:** Управляемые облачные решения от крупных провайдеров

**Решение:**

Выбран Apache Kafka.

**Обоснование:**

- **Высокая пропускная способность:** Способен обрабатывать сотни тысяч сообщений в секунду, что критично для обновлений статуса парковочных мест
- **Горизонтальная масштабируемость:** Легко масштабируется добавлением новых брокеров в кластер
- **Надежность хранения:** Сообщения сохраняются на диск и реплицируются, обеспечивая durability
- **Поддержка потоковой обработки:** Встроенные возможности для обработки потоков данных в реальном времени
- **Экосистема:** Богатый набор инструментов для мониторинга, управления и интеграции (Kafka Connect, Schema Registry)
- **Производительность при росте объема данных:** Сохраняет высокую производительность даже при больших объемах исторических данных

**Почему не другие варианты:**

- **RabbitMQ:** Может стать узким местом при очень высоких нагрузках, менее эффективен для очень больших объемов сообщений
- **NATS:** Хотя JetStream добавляет persistence, экосистема менее развита чем у Kafka
- **Управляемые облачные решения:** Создают vendor lock-in и могут быть дороже при больших объемах данных

**Последствия:**

- Необходимо развернуть и поддерживать Kafka-кластер с должным уровнем репликации и мониторинга
- Требуется внедрение Schema Registry для управления схемами сообщений
- Необходимо обучение команды работе с Kafka и его экосистемой
- Следует разработать стратегию retention policy для различных топиков
- Требуется внедрение мониторинга lag потребителей и производительности кластера
- Необходимо предусмотреть механизмы обработки ошибок и dead letter queues
- Следует стандартизировать форматы сообщений (Avro/Protobuf) для обеспечения совместимости